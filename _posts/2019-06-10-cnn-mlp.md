---
layout: post
title:  "Sparse multilayer perceptrons: converting CNNs to MLPs"
date:   2019-06-10 21:00:00 +0200
categories: machinelearning
---
This is a follow-up post to my last blog-post ([From OpenCV to TensorFlow and back: fast neural networks using OpenCV and C++](https://aul12.me/machinelearning/2019/06/07/mlp-cpp.html)) in which i wrote:

> The library is also strictly limited to feed-forward MLPs, neither CNNs nor architectures with feedback are possible.

While the part about feedback still holds, this is not the case with the part about CNNs. In this post i will present a way to convert a CNN (or any other [feedforward neural network](https://en.wikipedia.org/wiki/Feedforward_neural_network)) into a MLP. In the first part i will explain the theoretical background for this conversion, in the second part i will compare the performances of the equivalent networks, primarily using the OpenCV-MLP implementation running on a CPU.

## From convolution to matrix products
In recent years impressive results in computer vision have been achieved. Most of them are thanks to the rise of deep convolutional networks, such as [AlexNet](https://en.wikipedia.org/wiki/AlexNet), which started the CNN-Boom in 2012.

In contrast to fully connected MLPs, one value of the output (often refered to as a feature map for CNNs) is not influenced by all inputs, but only by inputs
which are close to the output. To exploit this simplification the input data requires some kind of spatial relation (a definition of "close"), such as pixel
neighborhood in an image and it requires for features to be local.

### Constraints
Without loss of generality i will restrict this derivation to input signals $$\in \mathbb{R}^{n \times m}$$, such as monochrome (grayscale) images.
This should suffice to demonstrate the approach while not overcomplicating things. 

I will also limit this derivation to networks where the current layer is only connected to the next layer and no layers are skipped for some data (this is for example the case for [feature pyramid networks](https://arxiv.org/abs/1612.03144)), for these kind of networks the skipped layers need to be enlarger and setup such that they represent the identity.

In the field of neural networks the operation refered to as convolution is often actually implemented as a correlation. This doesn't change much in this context, as changing from convolution to correlation and vice versa just requires mirroring the kernel on both axis, but certain properties of convolution do not hold (such as the convolution theorem). For this reason i will use the correlation instead of the convolution.

To simplify this further i will ignore the topic of boundary conditions, more details can be found on [wikipedia](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Edge_Handling).

### Derivation
Assume $$M \in \mathbb{R}^{n \times m}$$ is the input signal, $$K \in \mathbb{R}^{2 \cdot k + 1\times 2 \cdot k + 1}$$ is the convolution kernel (the "filter"),
$$O \in \mathbb{R}^{n \times m}$$ is the output signal with $$n,m,k \in \mathbb{N}$$

The discrete convolution is defined as:

$$O(y,x) = \sum_{i=-k}^k \sum_{j=-k}^k M(y+i,x+j) \cdot K(i+k, j+k)$$

now we define a matrix $$W_{x y} \in \mathbb{R}^{n \times m}$$ as

$$ W_{y x}(\chi, \upsilon) = \begin{cases}
    K(\chi-x+k,\upsilon-y+k) & x-k \leq \chi \leq x+k \land y-k \leq \upsilon \leq y+k \\
    0 & \text{otherwise}
\end{cases}$$


### A word on pooling 
stride


## Evaluation of the performance
